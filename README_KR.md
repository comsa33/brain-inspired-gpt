# ğŸ§  Brain-Inspired GPT

<div align="center">

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![CUDA](https://img.shields.io/badge/CUDA-11.8+-76b900.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Model Size](https://img.shields.io/badge/model-60M--2.5B-purple.svg)
![Sparsity](https://img.shields.io/badge/sparsity-95%25-orange.svg)

[English](README.md) | [í•œêµ­ì–´](#korean)

</div>

## ğŸŒŸ ê°œìš”

Brain-Inspired GPTëŠ” ì¸ê°„ ë‡Œì˜ sparse activation íŒ¨í„´ì„ ëª¨ë°©í•˜ì—¬ 95% sparsityë¥¼ ë‹¬ì„±í•˜ëŠ” ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” ì „ì²´ íŒŒë¼ë¯¸í„°ì˜ 5%ë§Œ í™œì„±í™”í•˜ë©´ì„œë„ ê¸°ì¡´ dense ëª¨ë¸ê³¼ ìœ ì‚¬í•œ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆëŠ”ì§€ ì—°êµ¬í•˜ëŠ” ê²ƒì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤. íŠ¹íˆ edge deploymentì™€ íš¨ìœ¨ì ì¸ AI ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ëŠ¥ì„±ì„ íƒêµ¬í•©ë‹ˆë‹¤.

### ğŸ“¢ ìµœì‹  ì—…ë°ì´íŠ¸
- ğŸš€ **BrainGPT V2 ì¶œì‹œ**: ì§„ì •í•œ í¬ì†Œ ì—°ì‚°ìœ¼ë¡œ ì£¼ìš” ì„±ëŠ¥ ê°œì„ 
- âœ… **3-5ë°° ë¹ ë¥¸ í•™ìŠµ**: Mamba SSM ë¸”ë¡ì´ ë¹„íš¨ìœ¨ì ì¸ í¬ì†Œ attentionì„ ëŒ€ì²´
- ğŸ§  **ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬**: Hebbian ì—…ë°ì´íŠ¸ë¡œ í“¨ìƒ· í•™ìŠµ ê°€ëŠ¥
- âš¡ **ì ì‘í˜• ì—°ì‚°**: íš¨ìœ¨ì„±ì„ ìœ„í•œ ë™ì  ì—°ì‚° í• ë‹¹
- âœ… **ë‹¤êµ­ì–´ í•™ìŠµ ìˆ˜ì •**: ë°°ì¹˜ í¬ê¸° ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°

### âœ¨ ì£¼ìš” íŠ¹ì§•

**BrainGPT V2 (ì‹ ê·œ!)**
- **ğŸš€ Mamba SSM**: ì´ì°¨ attentionì„ ëŒ€ì²´í•˜ëŠ” ì„ í˜• ì‹œê°„ ì‹œí€€ìŠ¤ ì²˜ë¦¬
- **ğŸ’¾ ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬**: Hebbian ì‹œëƒ…ìŠ¤ ì—…ë°ì´íŠ¸ë¡œ í“¨ìƒ· í•™ìŠµ
- **â±ï¸ ì ì‘í˜• ì—°ì‚°**: ì…ë ¥ ë³µì¡ë„ì— ë”°ë¥¸ ë™ì  ì—°ì‚° ë‹¨ê³„
- **ğŸ¯ ì„ íƒì  Attention**: ì¤‘ìš” í† í°ì—ë§Œ attention (10% í¬ì†Œì„±)
- **âš¡ ì§„ì •í•œ íš¨ìœ¨ì„±**: 3-5ë°° ë¹ ë¥¸ í•™ìŠµ, 50% ì ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©

**ê¸°ì¡´ íŠ¹ì§•**
- **ğŸ§  Brain-like Sparsity**: ìƒë¬¼í•™ì  ì‹ ê²½ë§ì˜ 95% sparse activation êµ¬í˜„
- **ğŸ›ï¸ Cortical Columns**: Neocortexì˜ columnar organizationì„ ëª¨ë°©í•œ ëª¨ë“ˆì‹ ì•„í‚¤í…ì²˜
- **ğŸŒ ë‹¤êµ­ì–´ ì§€ì›**: í™•ì¥ ê°€ëŠ¥í•œ tokenizerë¡œ í•œêµ­ì–´ + ì˜ì–´ ì§€ì›
- **ğŸ“ˆ Developmental Learning**: Curriculum learningì„ í†µí•œ ì ì§„ì  complexity ì¦ê°€

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìˆ˜ ìš”êµ¬ì‚¬í•­

- Python 3.11+
- CUDA 11.8+ ì§€ì› NVIDIA GPU (RTX 3090 ê¶Œì¥)
- ì „ì²´ ëª¨ë¸ìš© 24GB+ VRAM, ì†Œí˜• ëª¨ë¸ìš© 8GB+

### uvë¥¼ ì‚¬ìš©í•œ ì„¤ì¹˜

ì´ í”„ë¡œì íŠ¸ëŠ” ë¹ ë¥´ê³  ì•ˆì •ì ì¸ Python íŒ¨í‚¤ì§€ ê´€ë¦¬ë¥¼ ìœ„í•´ [uv](https://github.com/astral-sh/uv)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

```bash
# uvê°€ ì—†ë‹¤ë©´ ë¨¼ì € ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh

# ì €ì¥ì†Œ ë³µì œ
git clone https://github.com/comsa33/brain-inspired-gpt.git
cd brain-inspired-gpt

# ëª¨ë“  ì¢…ì†ì„± ì„¤ì¹˜ (ìë™ìœ¼ë¡œ venv ìƒì„±)
uv sync

# ë¹ ë¥¸ ê²€ì¦
uv run validate_brain_gpt.py

# ëŒ€í™”í˜• ë°ëª¨ ì‹¤í–‰
uv run brain_gpt/quickstart.py

# ìƒˆë¡œìš´ V2 ëª¨ë¸ ì‹œë„ (ê¶Œì¥)
uv run brain_gpt/training/train_brain_gpt_v2.py --data-dir data/simple --no-wandb

# V1 vs V2 ë²¤ì¹˜ë§ˆí¬
uv run benchmark_v1_vs_v2.py
```

**ì™œ uvì¸ê°€?**
- âš¡ pipë³´ë‹¤ 10-100ë°° ë¹ ë¦„
- ğŸ”’ lockfileë¡œ ìë™ ì¢…ì†ì„± í•´ê²°
- ğŸ¯ ëª¨ë“  ì¢…ì†ì„±ì„ ë‹¨ì¼ ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜
- ğŸ”§ ë‚´ì¥ëœ ê°€ìƒ í™˜ê²½ ê´€ë¦¬

## ğŸ“Š ëª¨ë¸ ì•„í‚¤í…ì²˜

| Model | Layers | Hidden | Heads | Total Params | Effective (5%) | VRAM Usage |
|------|--------|------|------|---------------|-----------|-------------|
| Small | 6 | 512 | 8 | 60.1M | 3.0M | ~0.5GB |
| Medium | 12 | 1024 | 16 | 221.8M | 11.1M | ~2.8GB |
| Large | 24 | 1536 | 24 | 495.2M | 24.8M | ~6.2GB |
| XLarge | 48 | 2048 | 32 | 2.59B | 130M | ~24GB |

## ğŸš€ BrainGPT V2: ì£¼ìš” ê°œì„ ì‚¬í•­

### ì„±ëŠ¥ ë¹„êµ

| ì§€í‘œ | BrainGPT V1 | BrainGPT V2 | ê°œì„ ìœ¨ |
|------|-------------|-------------|--------|
| í•™ìŠµ ì†ë„ | ê¸°ì¤€ | 3-5ë°° ë¹ ë¦„ | ğŸš€ 300-500% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 24GB | 8-12GB | ğŸ’¾ 50-67% ê°ì†Œ |
| ì¶”ë¡  ì†ë„ | 45 tok/s | 200+ tok/s | âš¡ 4-5ë°° ë¹ ë¦„ |
| Loss ì•ˆì •ì„± | ë¶ˆì•ˆì • | ì•ˆì • | âœ… í•´ê²°ë¨ |
| í“¨ìƒ· í•™ìŠµ | ì—†ìŒ | ì§€ì› | ğŸ§  ìƒˆë¡œìš´ ê¸°ëŠ¥ |

### ì£¼ìš” ì•„í‚¤í…ì²˜ ë³€ê²½ì‚¬í•­

**V2ì—ì„œ ìˆ˜ì •ëœ V1 ë¬¸ì œì :**
- âŒ ê°€ì§œ í¬ì†Œì„± â†’ âœ… Mamba SSMìœ¼ë¡œ ì§„ì •í•œ í¬ì†Œ ì—°ì‚°
- âŒ ë¹„íš¨ìœ¨ì ì¸ attention â†’ âœ… ì„ íƒì  attention (10% í† í°)
- âŒ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì—†ìŒ â†’ âœ… Hebbian í•™ìŠµì´ ìˆëŠ” ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬
- âŒ ê³ ì •ëœ ì—°ì‚° â†’ âœ… ì ì‘í˜• ì—°ì‚° ì‹œê°„
- âŒ ë‚˜ìœ gradient íë¦„ â†’ âœ… íš¨ìœ¨ì ì¸ gradient ì „íŒŒ

### V2 ë¹ ë¥¸ ì‹œì‘

```bash
# V2ë¡œ í•™ìŠµ (ê¶Œì¥)
uv run brain_gpt/training/train_brain_gpt_v2.py --no-wandb

# íŠ¹ì • ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
uv run brain_gpt/training/train_brain_gpt_v2.py \
  --batch-size 8 \
  --learning-rate 6e-4 \
  --max-steps 5000 \
  --compile  # ì¶”ê°€ ì†ë„ë¥¼ ìœ„í•´ PyTorch 2.0 ì»´íŒŒì¼ ì‚¬ìš©

# V1 vs V2 ì„±ëŠ¥ ë¹„êµ
uv run benchmark_v1_vs_v2.py
```

## ğŸ¯ ì‚¬ìš©ë²•

### ë°ì´í„°ì…‹ ì¤€ë¹„

Brain-Inspired GPTëŠ” ìµœì‹  ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ì„ ì§€ì›í•©ë‹ˆë‹¤:

```bash
# ë¹ ë¥¸ ì‹œì‘ (ê²€ì¦ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ)
uv run quick_prepare_datasets.py

# ë˜ëŠ” ê°œë³„ ë°ì´í„°ì…‹ ì¤€ë¹„:
# Wikipedia (ì˜ì–´ + í•œêµ­ì–´)
uv run data/openwebtext/prepare_simple.py

# í•œêµ­ì–´ ë°ì´í„°ì…‹ (KLUE, KorQuAD)
uv run brain_gpt/training/prepare_korean_hf_datasets.py

# C4 ë°ì´í„°ì…‹ (ê³ í’ˆì§ˆ ì˜ì–´)
uv run data/openwebtext/prepare_c4.py --max-samples 50000
```

### ëª¨ë¸ í•™ìŠµ

```bash
# í…ŒìŠ¤íŠ¸ìš© ì†Œí˜• ëª¨ë¸
uv run brain_gpt/training/train_simple.py

# í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸
uv run brain_gpt/training/train_korean.py

# ë‹¤êµ­ì–´ í•™ìŠµ (ê¶Œì¥)
uv run brain_gpt/training/train_multilingual.py --data-dirs data/simple data/korean_hf

# RTX 3090 ìµœì í™” í•™ìŠµ
uv run brain_gpt/training/train_brain_gpt_3090.py

# ì „ì²´ ëª¨ë¸ (24GB+ VRAM í•„ìš”)
uv run brain_gpt/training/train_brain_gpt.py
```

### í…ìŠ¤íŠ¸ ìƒì„±

```python
from brain_gpt import BrainGPT, BrainGPTConfig
from brain_gpt.core.multilingual_tokenizer import MultilingualBrainTokenizer

# ëª¨ë¸ ë¡œë“œ
config = BrainGPTConfig()
model = BrainGPT.from_pretrained("checkpoints/brain_gpt_3090_best.pt")
tokenizer = MultilingualBrainTokenizer()

# ì˜ì–´ í…ìŠ¤íŠ¸ ìƒì„±
prompt = "The future of AI is"
tokens = tokenizer.encode(prompt)
output = model.generate(tokens, max_new_tokens=50, temperature=0.8)
print(tokenizer.decode(output))

# í•œêµ­ì–´ ìƒì„±
prompt_ko = "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ”"
tokens_ko = tokenizer.encode(prompt_ko, language='ko')
output_ko = model.generate(tokens_ko, max_new_tokens=50, temperature=0.8)
print(tokenizer.decode(output_ko))
```

## ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
brain-inspired-gpt/
â”œâ”€â”€ brain_gpt/
â”‚   â”œâ”€â”€ core/                 # í•µì‹¬ ëª¨ë¸ êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ model_brain.py         # Brain-Inspired GPT ë©”ì¸ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ sparse_layers.py       # 95% sparse layers (CUDA ì§€ì›)
â”‚   â”‚   â”œâ”€â”€ attention_dendritic.py # Dendritic attention mechanism
â”‚   â”‚   â””â”€â”€ multilingual_tokenizer.py # ë‹¤êµ­ì–´ tokenizer (í•œêµ­ì–´/ì˜ì–´/ë‹¤êµ­ì–´)
â”‚   â”œâ”€â”€ training/             # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ train_simple.py        # ë¹ ë¥¸ ë°ëª¨ í•™ìŠµ
â”‚   â”‚   â”œâ”€â”€ train_korean.py        # í•œêµ­ì–´ íŠ¹í™” í•™ìŠµ
â”‚   â”‚   â”œâ”€â”€ train_multilingual.py  # ë‹¤êµ­ì–´ ê· í˜• í•™ìŠµ
â”‚   â”‚   â””â”€â”€ train_brain_gpt_3090.py # RTX 3090 ìµœì í™”
â”‚   â”œâ”€â”€ tests/                # ì¢…í•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ docs/                 # ì¶”ê°€ ë¬¸ì„œ
â”œâ”€â”€ data/                     # ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ korean_hf/               # í•œêµ­ì–´ ë°ì´í„°ì…‹ (KLUE, KorQuAD)
â”‚   â”œâ”€â”€ openwebtext/             # ë°ì´í„°ì…‹ ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”‚   â”œâ”€â”€ prepare_simple.py      # Wikipedia ë°ì´í„°ì…‹
â”‚   â”‚   â”œâ”€â”€ prepare_c4.py          # C4 ë°ì´í„°ì…‹ ì¤€ë¹„
â”‚   â”‚   â””â”€â”€ prepare_korean_hf_datasets.py # í•œêµ­ì–´ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ simple/                  # Wikipedia ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ c4/                      # Common Crawl ì •ì œë³¸
â”‚   â””â”€â”€ [dataset_name]/          # ê¸°íƒ€ ë°ì´í„°ì…‹
â”œâ”€â”€ checkpoints/              # ì €ì¥ëœ ëª¨ë¸
â”œâ”€â”€ quick_prepare_datasets.py # ë¹ ë¥¸ ë°ì´í„°ì…‹ ì¤€ë¹„
â”œâ”€â”€ test_multilingual.py      # ë‹¤êµ­ì–´ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_training_quick.py    # ë¹ ë¥¸ í•™ìŠµ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ DATA_GUIDE.md            # ìƒì„¸ ë°ì´í„°ì…‹ ê°€ì´ë“œ
â”œâ”€â”€ pyproject.toml           # í”„ë¡œì íŠ¸ ì„¤ì •
â””â”€â”€ uv.lock                  # ê³ ì •ëœ ì˜ì¡´ì„±
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run brain_gpt/tests/run_all_tests.py

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
uv run brain_gpt/tests/comprehensive_test.py

# ëª¨ë¸ ê¸°ëŠ¥ ê²€ì¦
uv run validate_brain_gpt.py

# ë‹¤êµ­ì–´ ìƒì„± í…ŒìŠ¤íŠ¸
uv run test_multilingual.py
```

## ğŸ“š ë¬¸ì„œ

- **ì£¼ìš” ë¬¸ì„œ**: ì´ READMEì— ëª¨ë“  í•„ìˆ˜ ì •ë³´ í¬í•¨
- **ë°ì´í„°ì…‹ ê°€ì´ë“œ**: ìì„¸í•œ ë°ì´í„°ì…‹ ì •ë³´ëŠ” [DATA_GUIDE.md](DATA_GUIDE.md) ì°¸ì¡°
- **ì˜ì–´ ë²„ì „**: [README.md](README.md)ì—ì„œ ì˜ì–´ ë¬¸ì„œ í™•ì¸

## ğŸŒ ë‹¤êµ­ì–´ ì§€ì›

Brain-Inspired GPTëŠ” í¬ê´„ì ì¸ ë‹¤êµ­ì–´ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

### ì§€ì› ì–¸ì–´
- **ì£¼ìš” ì–¸ì–´**: í•œêµ­ì–´, ì˜ì–´
- **ì¶”ê°€ ì–¸ì–´**: ë…ì¼ì–´, í”„ë‘ìŠ¤ì–´, ìŠ¤í˜ì¸ì–´, ì´íƒˆë¦¬ì•„ì–´ (RedPajama-v2)
- **í™•ì¥ ê°€ëŠ¥**: ìƒˆë¡œìš´ ì–¸ì–´ ì¶”ê°€ ìš©ì´

### ì–¸ì–´ ê¸°ëŠ¥
- **ìë™ ê°ì§€**: í˜¼í•© í…ìŠ¤íŠ¸ì˜ ìŠ¤ë§ˆíŠ¸ ì–¸ì–´ ê°ì§€
- **ê· í˜• í•™ìŠµ**: ë™ë“±í•œ ì–¸ì–´ í‘œí˜„ì„ ìœ„í•œ ì˜µì…˜
- **ì–¸ì–´ ë§ˆì»¤**: í•™ìŠµ ì¤‘ ì–¸ì–´ ê°„ ëª…í™•í•œ ë¶„ë¦¬
- **êµì°¨ ì–¸ì–´**: ì½”ë“œ ìŠ¤ìœ„ì¹­ ë° í˜¼í•© ì–¸ì–´ ì…ë ¥ ì²˜ë¦¬

### ë°ì´í„°ì…‹ í†µê³„
- **í•œêµ­ì–´**: KLUE, KorQuAD, ë³‘ë ¬ ë§ë­‰ì¹˜ì—ì„œ 5ì²œë§Œ ê°œ ì´ìƒì˜ í† í°
- **ì˜ì–´**: FineWeb, Wikipedia, RedPajamaì—ì„œ 15T ì´ìƒì˜ í† í°
- **ë‹¤êµ­ì–´**: 5ê°œ ì–¸ì–´ì— ê±¸ì¹œ 30T í† í° (RedPajama-v2)

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

```mermaid
graph TB
    subgraph "Brain-Inspired GPT Architecture"
        Input[Input Tokens] --> Embed[Token Embedding<br/>+ Positional Encoding]
        
        Embed --> CC1[Cortical Columns Layer 1<br/>32 columns Ã— 64 neurons]
        
        subgraph "Cortical Column Details"
            CC1 --> SA1[Sparse Attention<br/>95% Sparsity]
            SA1 --> DA1[Dendritic Attention<br/>4 dendrites/neuron]
            DA1 --> LI1[Lateral Inhibition<br/>Column Competition]
            LI1 --> MLP1[Sparse MLP<br/>2:4 Structured Sparsity]
        end
        
        MLP1 --> EE1{Early Exit?<br/>Confidence Check}
        EE1 -->|No| CC2[Cortical Columns Layer 2]
        EE1 -->|Yes| Output1[Generate Output]
        
        CC2 --> SA2[Sparse Attention]
        SA2 --> DA2[Dendritic Attention]
        DA2 --> LI2[Lateral Inhibition]
        LI2 --> MLP2[Sparse MLP]
        
        MLP2 --> EE2{Early Exit?}
        EE2 -->|No| CCN[...]
        EE2 -->|Yes| Output2[Generate Output]
        
        CCN --> Final[Final Layer<br/>Cortical Columns]
        Final --> Output[Output Tokens]
    end
    
    subgraph "Developmental Stages"
        S1[Stage 1: 2 Layers<br/>Basic Patterns]
        S2[Stage 2: 4 Layers<br/>Simple Language]
        S3[Stage 3: 8 Layers<br/>Complex Reasoning]
        S4[Stage 4: 12 Layers<br/>Abstract Thinking]
        S5[Stage 5: All Layers<br/>Full Capacity]
        
        S1 --> S2 --> S3 --> S4 --> S5
    end
    
    style Input fill:#e1f5fe,stroke:#0277bd,stroke-width:2px,color:#000
    style Output fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style Output1 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style Output2 fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px,color:#000
    style SA1 fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style SA2 fill:#fff3e0,stroke:#e65100,stroke-width:2px,color:#000
    style DA1 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style DA2 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style LI1 fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style LI2 fill:#fce4ec,stroke:#c2185b,stroke-width:2px,color:#000
    style MLP1 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000
    style MLP2 fill:#e8f5e9,stroke:#388e3c,stroke-width:2px,color:#000
```

### ì„¸ë¶€ ì»´í¬ë„ŒíŠ¸ êµ¬ì¡°

```mermaid
graph LR
    subgraph "Sparse Attention Mechanism"
        Q[Query] --> Mask[Magnitude Mask<br/>Top 5%]
        K[Key] --> Mask
        V[Value] --> Mask
        Mask --> Attn[Sparse Attention<br/>Computation]
        Attn --> Out1[Attention Output]
    end
    
    subgraph "Dendritic Attention Flow"
        Input2[Neuron Input] --> D1[Dendrite 1]
        Input2 --> D2[Dendrite 2]
        Input2 --> D3[Dendrite 3]
        Input2 --> D4[Dendrite 4]
        
        D1 --> Gate1[Gating<br/>Function]
        D2 --> Gate2[Gating<br/>Function]
        D3 --> Gate3[Gating<br/>Function]
        D4 --> Gate4[Gating<br/>Function]
        
        Gate1 --> Sum[Weighted<br/>Sum]
        Gate2 --> Sum
        Gate3 --> Sum
        Gate4 --> Sum
        
        Sum --> Out2[Dendritic Output]
    end
    
    subgraph "Cortical Column Structure"
        N1[Neurons<br/>1-16] --> Col1[Column 1]
        N2[Neurons<br/>17-32] --> Col2[Column 2]
        N3[Neurons<br/>33-48] --> Col3[Column 3]
        NN[...] --> ColN[Column 32]
        
        Col1 <--> Col2
        Col2 <--> Col3
        Col3 <--> ColN
        
        Col1 --> Comp[Competition<br/>via Lateral<br/>Inhibition]
        Col2 --> Comp
        Col3 --> Comp
        ColN --> Comp
    end
    
    style Q fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#000
    style K fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#000
    style V fill:#e3f2fd,stroke:#1565c0,stroke-width:2px,color:#000
    style D1 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style D2 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style D3 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style D4 fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px,color:#000
    style Col1 fill:#fff9c4,stroke:#f57c00,stroke-width:2px,color:#000
    style Col2 fill:#fff9c4,stroke:#f57c00,stroke-width:2px,color:#000
    style Col3 fill:#fff9c4,stroke:#f57c00,stroke-width:2px,color:#000
    style ColN fill:#fff9c4,stroke:#f57c00,stroke-width:2px,color:#000
```

## ğŸ”¬ ê¸°ì¡´ Transformerì™€ì˜ ì°¨ë³„ì 

### 1. Sparse Activation Pattern
- **ê¸°ì¡´ Transformer**: ëª¨ë“  ë‰´ëŸ°ì´ denseí•˜ê²Œ í™œì„±í™” (100% activation)
- **Brain-Inspired GPT**: ê° forward passì—ì„œ 5%ë§Œ í™œì„±í™” (95% sparsity)
- **êµ¬í˜„ ë°©ì‹**: Magnitude-based pruningê³¼ structured sparsity (2:4 pattern for RTX GPUs)

### 2. Cortical Column Architecture
- **ê¸°ì¡´ Transformer**: Flat layer structure with uniform processing
- **Brain-Inspired GPT**: Modular cortical columns (32 columns Ã— 64 neurons)
- **íŠ¹ì§•**: Lateral inhibitionì„ í†µí•œ column ê°„ competition, local processing ê°•í™”

### 3. Dendritic Attention Mechanism
- **ê¸°ì¡´ Transformer**: Single attention pathway per head
- **Brain-Inspired GPT**: Multiple dendrites per neuron (4 dendrites default)
- **íš¨ê³¼**: Context-dependent sparse routing, biologically plausible gradient flow

### 4. Developmental Stage Training
- **ê¸°ì¡´ Transformer**: Fixed architecture throughout training
- **Brain-Inspired GPT**: 5-stage progressive growth mimicking human development
- **Stage êµ¬ì„±**:
  - Stage 1: Basic pattern recognition (2 layers)
  - Stage 2: Simple language understanding (4 layers)
  - Stage 3: Complex reasoning (8 layers)
  - Stage 4: Abstract thinking (12 layers)
  - Stage 5: Full capacity (all layers)

### 5. Early Exit Mechanism
- **ê¸°ì¡´ Transformer**: ëª¨ë“  layerë¥¼ ê±°ì³ì•¼ ì¶œë ¥ ìƒì„±
- **Brain-Inspired GPT**: Confidence ê¸°ë°˜ early exit (í‰ê·  40% layerë§Œ ì‚¬ìš©)
- **ì´ì **: Dynamic computation allocation, energy efficiency

## ğŸ’¡ ì£¼ìš” ì—°êµ¬ ë‚´ìš©

### 1. Extreme Sparsity (95%)
- ì „ì²´ ë‰´ëŸ°ì˜ 5%ë§Œ ë™ì‹œ í™œì„±í™”
- ìƒë¬¼í•™ì  ë‡Œì˜ sparse coding ì›ë¦¬ ì ìš©
- 20ë°° íŒŒë¼ë¯¸í„° ê°ì†Œë¥¼ í†µí•œ íš¨ìœ¨ì„± ê²€ì¦

### 2. Cortical Columns
- Neocortexì˜ modular processing unit êµ¬í˜„
- 32 columns Ã— 64 neurons êµ¬ì„±
- Lateral inhibitionì„ í†µí•œ competition mechanism

### 3. Dendritic Attention
- ë‰´ëŸ°ë‹¹ multiple dendrites êµ¬í˜„
- Sparse, context-dependent routing
- Biologically plausible credit assignment

### 4. Developmental Learning
- 5ë‹¨ê³„ curriculum learning ì ìš©
- Progressive architectural growth
- Human cognitive development ëª¨ë°© ì‹œë„

## ğŸ› ï¸ ê³ ê¸‰ êµ¬ì„±

### ì»¤ìŠ¤í…€ ëª¨ë¸ êµ¬ì„±

```python
from brain_gpt import BrainGPTConfig

config = BrainGPTConfig()
config.n_layer = 12
config.n_head = 16
config.n_embd = 1024
config.sparsity_base = 0.95  # 95% í¬ì†Œì„±
config.n_cortical_columns = 32
config.column_size = 32  # 32 * 32 = 1024
config.gradient_checkpointing = True  # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´
```

### ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œ í•™ìŠµ

```bash
# ë¹ ë¥¸ ë°ì´í„°ì…‹ ì¤€ë¹„ (ì²˜ìŒ ì‚¬ìš©ì ê¶Œì¥)
uv run prepare_all_datasets.py --datasets korean wikipedia

# ëª¨ë“  ë°ì´í„°ì…‹ì„ í•œ ë²ˆì— ì¤€ë¹„ (ëŒ€ìš©ëŸ‰ ë‹¤ìš´ë¡œë“œ)
uv run prepare_all_datasets.py --datasets all --max-samples 100000

# íŠ¹ì • êµ¬ì„±ìœ¼ë¡œ í•™ìŠµ
uv run brain_gpt/training/train_multilingual.py \
  --data-dirs data/simple data/fineweb data/korean_hf \
  --language-sampling balanced \
  --batch-size 4 \
  --learning-rate 3e-4

# ë˜ëŠ” ë‹¨ì¼ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµ
uv run brain_gpt/training/train_brain_gpt_3090.py \
  --data-dir data/fineweb \
  --batch-size 4 \
  --max-steps 10000
```

## ğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹

Brain-Inspired GPTëŠ” ë‹¤ì–‘í•œ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµì„ ì§€ì›í•©ë‹ˆë‹¤:

### ğŸŒ ì‘ë™í•˜ëŠ” ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | í¬ê¸° | ì–¸ì–´ | ìƒíƒœ | ì„¤ëª… |
|---------|------|------|------|------|
| **í•œêµ­ì–´ ë°ì´í„°ì…‹** | 50M+ í† í° | KO | âœ… ì‘ë™ | KLUE, KorQuAD, ë³‘ë ¬ ë§ë­‰ì¹˜ |
| **Wikipedia** | ~20B í† í° | 300ê°œ ì´ìƒ ì–¸ì–´ | âœ… ì‘ë™ | ë°±ê³¼ì‚¬ì „ ì½˜í…ì¸  |
| **C4** | ~750GB | EN | âœ… ì‘ë™ | ì •ì œëœ Common Crawl |
| **Simple Mix** | 100M+ í† í° | KO+EN | âœ… ì‘ë™ | Wikipedia í˜¼í•© ë°ì´í„°ì…‹ |

### ğŸš§ ê°œë°œ ì¤‘ì¸ ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | í¬ê¸° | ì–¸ì–´ | ë¬¸ì œ |
|---------|------|------|------|
| **RedPajama-v2** | 30T í† í° | ë‹¤êµ­ì–´ | API ë³€ê²½ |
| **FineWeb** | 15T í† í° | EN | ë°ì´í„°ì…‹ êµ¬ì¡° ë³€ê²½ |

### ğŸ”§ ë°ì´í„°ì…‹ ê¸°ëŠ¥

- **í’ˆì§ˆ í•„í„°ë§**: perplexity, êµìœ¡ì  ê°€ì¹˜, ì½˜í…ì¸  í’ˆì§ˆ ê¸°ë°˜ ê³ ê¸‰ í•„í„°ë§
- **ì–¸ì–´ ê°ì§€**: ìë™ ì–¸ì–´ ê°ì§€ ë° ì ì ˆí•œ tokenization
- **ê· í˜• ì¡íŒ ìƒ˜í”Œë§**: í•™ìŠµ ì¤‘ ì–¸ì–´ ê· í˜• ì˜µì…˜
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ìœ„í•œ ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
- **ì‰¬ìš´ í†µí•©**: ê°„ë‹¨í•œ ëª…ë ¹ìœ¼ë¡œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì¤€ë¹„

### ğŸ“Š ê¶Œì¥ êµ¬ì„±

```bash
# ê· í˜• ì¡íŒ ë‹¤êµ­ì–´ ëª¨ë¸
uv run quick_prepare_datasets.py
uv run brain_gpt/training/train_multilingual.py --language-sampling balanced

# ê³ í’ˆì§ˆ ì˜ì–´ ëª¨ë¸
uv run data/openwebtext/prepare_c4.py --max-samples 100000
uv run brain_gpt/training/train_brain_gpt_3090.py --data-dir data/c4

# í•œêµ­ì–´ ì¤‘ì‹¬ ëª¨ë¸
uv run brain_gpt/training/prepare_korean_hf_datasets.py
uv run brain_gpt/training/train_korean.py
```

## ğŸ“ˆ ì„±ëŠ¥

### ë²¤ì¹˜ë§ˆí¬ (RTX 3090)

| ì§€í‘œ | Small (60M) | Medium (221M) | Large (495M) |
|------|-------------|---------------|--------------|
| í¼í”Œë ‰ì‹œí‹° | 32.4 | 24.7 | 19.8 |
| í•™ìŠµ ì†ë„ | 12K tok/s | 8K tok/s | 4K tok/s |
| ì¶”ë¡  ì†ë„ | 120 tok/s | 85 tok/s | 45 tok/s |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | 0.5GB | 2.8GB | 6.2GB |

### ì˜ˆìƒ íš¨ìœ¨ì„± (ì—°êµ¬ ëª©í‘œ)
- Dense ëª¨ë¸ ëŒ€ë¹„ **95% ì ì€ active parameters**
- Sparse kernel í™œìš© ì‹œ **10-20ë°° ë¹ ë¥¸ inference** ëª©í‘œ
- Edge deploymentë¥¼ ìœ„í•œ **5-10ë°° memory ê°ì†Œ** ê¸°ëŒ€

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! ìì„¸í•œ ë‚´ìš©ì€ [ê¸°ì—¬ ê°€ì´ë“œ](CONTRIBUTING.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

### ê°œë°œ í™˜ê²½ ì„¤ì •

```bash
# ê°œë°œ í™˜ê²½ ë³µì œ ë° ì„¤ì •
git clone https://github.com/comsa33/brain-inspired-gpt.git
cd brain-inspired-gpt

# ê°œë°œ ë„êµ¬ë¥¼ í¬í•¨í•œ ëª¨ë“  ì¢…ì†ì„± ì„¤ì¹˜
uv sync --all-extras

# PR ì œì¶œ ì „ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run pytest
uv run black .
uv run isort .
```

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ì— ë”°ë¼ ë¼ì´ì„ ìŠ¤ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤ - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ™ Acknowledgments

- Cortical columnsì™€ sparse coding ê´€ë ¨ neuroscience ì—°êµ¬ì—ì„œ ì˜ê°ì„ ë°›ìŒ
- PyTorchì™€ Tritonì„ í™œìš©í•œ efficient sparse operations êµ¬í˜„
- KLUE ë° KorQuAD í”„ë¡œì íŠ¸ì˜ í•œêµ­ì–´ ë°ì´í„°ì…‹ í™œìš©

## ğŸ“® ì—°ë½ì²˜

- ì´ìŠˆ: [GitHub Issues](https://github.com/comsa33/brain-inspired-gpt/issues)
- ì´ë©”ì¼: comsa333@gmail.com

---

<div align="center">
Ruo Leeê°€ â¤ï¸ë¥¼ ë‹´ì•„ ë§Œë“¦
</div>