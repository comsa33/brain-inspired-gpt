<div align="center">

# ğŸ§  CortexGPT

**ì¸ê°„ ë‘ë‡Œì—ì„œ ì˜ê°ì„ ë°›ì€ ì‹¤ì‹œê°„ í•™ìŠµ ì–¸ì–´ ëª¨ë¸**

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)
![License](https://img.shields.io/badge/license-MIT-green.svg)
![Model Size](https://img.shields.io/badge/model-768D-purple.svg)
![Memory](https://img.shields.io/badge/memory-STMâ†’LTMâ†’Archive-orange.svg)

[English](README.md) | [í•œêµ­ì–´](#í•œêµ­ì–´)

</div>

## í•œêµ­ì–´

### ğŸ“– CortexGPT ì†Œê°œ

CortexGPTëŠ” ì¸ê°„ì˜ ë‡Œ í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ì„ ëª¨ë°©í•œ í˜ì‹ ì ì¸ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤. ê¸°ì¡´ ëª¨ë¸ë“¤ì´ í›ˆë ¨ê³¼ ì¶”ë¡ ì„ ë³„ë„ë¡œ ìˆ˜í–‰í•˜ëŠ” ê²ƒê³¼ ë‹¬ë¦¬, CortexGPTëŠ” ì¸ê°„ì²˜ëŸ¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤. ë‹¨ê¸° ê¸°ì–µ(STM), ì¥ê¸° ê¸°ì–µ(LTM), ë³´ê´€ ë©”ëª¨ë¦¬(Archive)ë¡œ êµ¬ì„±ëœ ìƒë¬¼í•™ì  ì˜ê°ì„ ë°›ì€ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ íŠ¹ì§•ìœ¼ë¡œ í•˜ë©°, ëª¨ë“  ìƒí˜¸ì‘ìš©ì—ì„œ í•™ìŠµí•˜ê³  ê¸°ì–µí•˜ë©´ì„œ ì§€ì‹ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” í˜ì‹ :
- **ì‹¤ì‹œê°„ ì§€ì† í•™ìŠµ** - í›ˆë ¨/ì¶”ë¡  êµ¬ë¶„ ì—†ì´ ê³„ì† í•™ìŠµ
- **ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬ ê³„ì¸µ** - íš¨ìœ¨ì ì¸ ì§€ì‹ ê´€ë¦¬
- **ê²½í—˜ ê¸°ë°˜ ìê¸° ê°œì„  ë©”ì»¤ë‹ˆì¦˜** - ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì„±ëŠ¥ í–¥ìƒ
- **ë„¤ì´í‹°ë¸Œ ë‹¤êµ­ì–´ ì§€ì›** - BGE-M3 ì„ë² ë”©ìœ¼ë¡œ 100ê°œ ì´ìƒ ì–¸ì–´ ì§€ì›
- **ì´ˆê³ ì† ë°ì´í„° ë¡œë”©** - ë¹„ë™ê¸° ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ì¦‰ì‹œ í›ˆë ¨ ì‹œì‘
- **í–¥ìƒëœ ì•ˆì •ì„±** - ì˜¨ë„ ì œì–´ ë©”ëª¨ë¦¬ ê²Œì´íŒ… (Phase 1)
- **ë‡Œê³¼í•™ ê¸°ë°˜ ê¸°ëŠ¥** - í•­ìƒì„± ê°€ì†Œì„± ë° ìˆ˜ë©´-ê°ì„± ì£¼ê¸° í¬í•¨ (Phase 2)
- **35ë°° ì„±ëŠ¥ í–¥ìƒ** - GPU ê°€ì† ë©”ëª¨ë¦¬ ë° ê³ ê¸‰ ì¸ì§€ ê¸°ëŠ¥ (Phase 3)

### ğŸ›ï¸ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    subgraph "CortexGPT ëª¨ë¸"
        Input["ğŸ“¥ ì…ë ¥ ë ˆì´ì–´<br/>â€¢ ë‹¤êµ­ì–´ í† í¬ë‚˜ì´ì €<br/>â€¢ í•œêµ­ì–´/ì˜ì–´ ì§€ì›<br/>â€¢ BPE ì¸ì½”ë”©"]
        
        Transformer["ğŸ¤– íŠ¸ëœìŠ¤í¬ë¨¸ ì½”ì–´<br/>â€¢ ë©€í‹° í—¤ë“œ ì–´í…ì…˜<br/>â€¢ í”¼ë“œ í¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬<br/>â€¢ ë ˆì´ì–´ ì •ê·œí™”<br/>â€¢ ì”ì°¨ ì—°ê²°"]
        
        subgraph "ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ"
            STM["ğŸ’­ STM (ë‹¨ê¸° ê¸°ì–µ)<br/>â€¢ ìš©ëŸ‰: 64<br/>â€¢ ë¹ ë¥¸ ì ‘ê·¼<br/>â€¢ ìµœê·¼ ìƒí˜¸ì‘ìš©"]
            LTM["ğŸ§  LTM (ì¥ê¸° ê¸°ì–µ)<br/>â€¢ ìš©ëŸ‰: 10,000<br/>â€¢ í†µí•©ëœ ì§€ì‹<br/>â€¢ ë¹ˆë²ˆí•œ íŒ¨í„´"]
            Archive["ğŸ“š Archive (ë³´ê´€ ë©”ëª¨ë¦¬)<br/>â€¢ ìš©ëŸ‰: 100,000<br/>â€¢ ì••ì¶• ì €ì¥<br/>â€¢ ë“œë¬¼ê²Œ ì‚¬ìš©ë˜ëŠ” ì§€ì‹"]
        end
        
        Learner["ğŸ“ ì‹¤ì‹œê°„ í•™ìŠµê¸°<br/>â€¢ ì˜¨ë¼ì¸ í•™ìŠµ<br/>â€¢ ë©”ëª¨ë¦¬ í†µí•©<br/>â€¢ ìê¸° í‰ê°€"]
        
        Output["ğŸ“¤ ì¶œë ¥ ë ˆì´ì–´<br/>â€¢ í† í° ìƒì„±<br/>â€¢ ì‹ ë¢°ë„ ì ìˆ˜<br/>â€¢ ì–¸ì–´ ê°ì§€"]
    end
    
    Input --> |"ì¸ì½”ë”©ëœ í† í°"| Transformer
    Transformer --> |"ì»¨í…ìŠ¤íŠ¸ ì €ì¥"| STM
    STM --> |"í†µí•©<br/>(ìì£¼ ì‚¬ìš©)"| LTM
    LTM --> |"ë³´ê´€<br/>(ë“œë¬¼ê²Œ ì‚¬ìš©)"| Archive
    STM --> |"í˜„ì¬ ì»¨í…ìŠ¤íŠ¸"| Learner
    LTM --> |"ê²€ìƒ‰ëœ ì§€ì‹"| Learner
    Learner --> |"ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸"| Transformer
    Transformer --> |"ì˜ˆì¸¡"| Output
    Learner -.-> |"ì—…ë°ì´íŠ¸"| STM
    Learner -.-> |"ì „ì†¡"| LTM
    
    style Input fill:#e6f3ff,stroke:#333,stroke-width:2px,color:#000
    style Transformer fill:#e6f3ff,stroke:#333,stroke-width:2px,color:#000
    style STM fill:#ffe6e6,stroke:#333,stroke-width:2px,color:#000
    style LTM fill:#e6ffe6,stroke:#333,stroke-width:2px,color:#000
    style Archive fill:#e6e6ff,stroke:#333,stroke-width:2px,color:#000
    style Learner fill:#e6f3ff,stroke:#333,stroke-width:2px,color:#000
    style Output fill:#e6f3ff,stroke:#333,stroke-width:2px,color:#000
```

### ğŸŒŸ í•µì‹¬ íŠ¹ì§•

- **ì‹¤ì‹œê°„ í•™ìŠµ**: í›ˆë ¨/ì¶”ë¡  êµ¬ë¶„ ì—†ì´ ì§€ì†ì ìœ¼ë¡œ í•™ìŠµ
- **ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë©”ëª¨ë¦¬**: STM(ë‹¨ê¸°) â†’ LTM(ì¥ê¸°) â†’ Archive(ë³´ê´€) ì‹œìŠ¤í…œ
- **ìê¸° ê°œì„ **: ìŠ¤ìŠ¤ë¡œ í‰ê°€í•˜ê³  ê°œì„ í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜
- **ë‹¤êµ­ì–´ ì§€ì›**: í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: OOM ë°©ì§€ë¥¼ ìœ„í•œ ì ì‘í˜• ë°°ì¹˜ í¬ê¸° ì¡°ì •
- **ì²´í¬í¬ì¸íŠ¸ ì§€ì›**: ì¤‘ë‹¨ í›„ í›ˆë ¨ ì¬ê°œ ê°€ëŠ¥
- **BGE-M3 ì„ë² ë”©**: ìµœì²¨ë‹¨ ë‹¤êµ­ì–´ ì„ë² ë”© (100ê°œ ì´ìƒ ì–¸ì–´, ê¸°ë³¸ í™œì„±í™”)

#### ğŸ†• ìµœì‹  ê°œì„ ì‚¬í•­ (v2.0)

**Phase 1 - í›ˆë ¨ ì•ˆì •ì„±**:
- ì˜¨ë„ ì œì–´ ë©”ëª¨ë¦¬ ê²Œì´íŒ…ìœ¼ë¡œ ìŠ¹ìë…ì‹ í˜„ìƒ ë°©ì§€
- ë©”ëª¨ë¦¬ ê²€ìƒ‰ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ ì¤‘ë‹¨ìœ¼ë¡œ í”¼ë“œë°± ë£¨í”„ ì œê±°
- ì†ì‹¤ ê¸‰ì¦ ê°ì§€ ë° ìë™ ë³µêµ¬
- Gumbel-Softmaxë¥¼ ì‚¬ìš©í•œ ë¶€ë“œëŸ¬ìš´ í¬ì†Œì„±ìœ¼ë¡œ ë§¤ë„ëŸ¬ìš´ ê·¸ë˜ë””ì–¸íŠ¸

**Phase 2 - neuroscience ê¸°ë°˜ ê¸°ëŠ¥**:
- ì•ˆì •ì ì¸ ë‰´ëŸ° ë°œí™”ìœ¨ì„ ìœ„í•œ í•­ìƒì„± ê°€ì†Œì„±
- ìˆ˜ë©´-ê°ì„± í†µí•© ì£¼ê¸° (ê°ì„±/NREM/REM ë‹¨ê³„)
- ë³´ì™„ í•™ìŠµ ì‹œìŠ¤í…œ (ë¹ ë¥¸ í•´ë§ˆ vs ëŠë¦° ì‹ í”¼ì§ˆ)
- BCM í•™ìŠµ ê·œì¹™ì„ ì‚¬ìš©í•œ ë©”íƒ€ê°€ì†Œì„±

**Phase 3 - ì„±ëŠ¥ ìµœì í™”**:
- FAISSë¥¼ ì‚¬ìš©í•œ GPU ê°€ì† ë©”ëª¨ë¦¬ (35ë°° ì†ë„ í–¥ìƒ: 3019.4 í† í°/ì´ˆ)
- ìŠ¤ë ˆë“œ í’€ì„ ì‚¬ìš©í•œ ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì‘ì—…
- ê²½í—˜ ì‹œí€€ìŠ¤ë¥¼ ìœ„í•œ ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬
- ì‘ì—…ë³„ ê²Œì´íŠ¸ê°€ ìˆëŠ” ì‘ì—… ë©”ëª¨ë¦¬
- ê³„ì¸µì  ë©”ëª¨ë¦¬ ì••ì¶•
- ê³ ê¸‰ ì¸ì§€ ê¸°ëŠ¥ (ìœ ì¶”, ì¸ê³¼ ì¶”ë¡ , ê°œë… í•™ìŠµ)

### ğŸš€ ë¹ ë¥¸ ì‹œì‘

> **ğŸ“– CortexGPTê°€ ì²˜ìŒì´ì‹ ê°€ìš”?** ìì„¸í•œ ì•ˆë‚´ì™€ best practicesëŠ” [Training Guide](TRAINING_GUIDE.md)ë¥¼ í™•ì¸í•˜ì„¸ìš”!

#### 1. ì„¤ì¹˜

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/comsa33/cortexgpt.git
cd cortexgpt

# ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜
uv sync

# ë˜ëŠ” ëª¨ë‹ˆí„°ë§ ë„êµ¬ í¬í•¨ ì„¤ì¹˜
uv sync --extra monitoring
```

#### 2. ë°ëª¨ ë°ì´í„° ìƒì„±

```bash
# ë°ëª¨ í›ˆë ¨ ë°ì´í„° ìƒì„±
uv run scripts/data/create_demo_data.py
```

#### 3. ë¹ ë¥¸ ì‹œì‘ (ì¶”ì²œ)

```bash
# ëŒ€í™”í˜• ê°€ì´ë“œë¡œ ì‹œì‘
uv run scripts/quick_start.py
```

ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ:

```bash
# í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸
uv run tests/demo_tokenizer.py

# ëª¨ë¸ í•™ìŠµ ê°€ëŠ¥ ì—¬ë¶€ í…ŒìŠ¤íŠ¸ (ê³¼ì í•© í…ŒìŠ¤íŠ¸)
uv run tests/test_overfit.py
```

#### 4. í›ˆë ¨ (v2.0 ì—…ë°ì´íŠ¸)

##### ì¤€ë¹„ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì‚¬ìš© (ê¶Œì¥)
```bash
# ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¹ ë¥¸ ë°ëª¨ í›ˆë ¨
uv run scripts/train_cortexgpt.py --epochs 10 --batch-size 8

# íŠ¹ì • ë°ì´í„° íŒŒì¼ ì§€ì •
uv run scripts/train_cortexgpt.py \
    --train-data data/sample_train.bin \
    --val-data data/sample_val.bin \
    --epochs 10

# ìµœì†Œ ëª¨ë“œ (ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”)
uv run scripts/train_cortexgpt.py --minimal --epochs 5 --batch-size 16

# KLUE í•œêµ­ì–´ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --epochs 20 --wandb

# ê³ ê¸‰ ë‡Œê³¼í•™ ê¸°ëŠ¥ (ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš© - RTX 3090ì€ ì•„ë˜ ì°¸ì¡°)
uv run scripts/train_cortexgpt.py \
    --enable-homeostasis \
    --enable-sleep-wake \
    --consolidation-cycle 1000 \
    --epochs 20

# GPU ê°€ì† ì„±ëŠ¥ ëª¨ë“œ
uv run scripts/train_cortexgpt.py \
    --use-gpu-memory \
    --async-memory \
    --enable-episodic \
    --enable-working \
    --epochs 20

# ì¤‘ë‹¨ëœ í›ˆë ¨ ì¬ê°œ
uv run scripts/train_cortexgpt.py \
    --resume checkpoints/cortex_unified/cortex_gpt_best.pt
```

##### JSONLì—ì„œ ë°ì´í„° ì¤€ë¹„
```bash
# JSONLì„ ë°”ì´ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
uv run cortexgpt/data/prepare_data.py \
    --input-file data/train.jsonl \
    --output-file data/custom_train.bin \
    --tokenizer gpt2

# ì¤€ë¹„ëœ ë°ì´í„°ë¡œ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/custom_train.bin \
    --val-data data/custom_val.bin \
    --epochs 10
```

ê³ ê¸‰ ì˜µì…˜:
```bash
uv run scripts/train_cortexgpt.py --help
```

#### 5. ë°ëª¨ ì‹¤í–‰ ë° ë²¤ì¹˜ë§ˆí¬

```bash
# ìµœì†Œ ìƒì„± ë°ëª¨
uv run scripts/demos/minimal_demo.py

# ì‹¤ì‹œê°„ í•™ìŠµ ë°ëª¨
uv run scripts/demos/learning_effect_demo.py

# ëŒ€í™”í˜• ì±„íŒ… ë°ëª¨
uv run scripts/demos/natural_language_demo.py

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
uv run scripts/benchmark.py --checkpoint checkpoints/model_best.pt
```

### ğŸ“– ìƒì„¸ ì‚¬ìš© ê°€ì´ë“œ

#### ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©í•˜ê¸°

```bash
# í†µí•© ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
uv run scripts/generate.py \
    --checkpoint checkpoints/cortex_unified/cortex_gpt_best.pt \
    --prompt "ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ëŠ”" \
    --max-length 100

# ì˜ì–´ í…ìŠ¤íŠ¸ ìƒì„±
uv run scripts/generate.py \
    --checkpoint checkpoints/cortex_unified/cortex_gpt_best.pt \
    --prompt "The future of AI is" \
    --temperature 0.8

# ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ ì‚¬ìš© (í˜¸í™˜ ê°€ëŠ¥)
uv run scripts/generate.py \
    --checkpoint checkpoints/model_best.pt \
    --prompt "ì•ˆë…•í•˜ì„¸ìš”" \
    --temperature 0.7
```

#### ì‹¤ì‹œê°„ í•™ìŠµ ë°ëª¨

ì‹¤ì‹œê°„ í•™ìŠµ ë°ëª¨ëŠ” CortexGPTê°€ ìƒí˜¸ì‘ìš©ì„ í†µí•´ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ ë³´ì—¬ì¤ë‹ˆë‹¤:

```bash
# í•™ìŠµ íš¨ê³¼ ë°ëª¨ ì‹¤í–‰
uv run scripts/demos/learning_effect_demo.py
```

ì´ ë°ëª¨ëŠ” ë‹¤ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤:
- ì§€ì‹ ì—†ì´ ì´ˆê¸° ì‘ë‹µ
- ì‚¬ìš©ì í”¼ë“œë°±ìœ¼ë¡œë¶€í„° í•™ìŠµ
- í•™ìŠµ í›„ ê°œì„ ëœ ì‘ë‹µ
- ì‹œê°„ì— ë”°ë¥¸ ë©”ëª¨ë¦¬ í†µí•©

#### ì»¤ìŠ¤í…€ í›ˆë ¨

ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì˜ ê²½ìš°, JSONL íŒŒì¼ë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:

```json
{"text": "ì—¬ê¸°ì— í›ˆë ¨ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"}
{"text": "ë˜ ë‹¤ë¥¸ í›ˆë ¨ ì˜ˆì œ"}
```

ê·¸ëŸ° ë‹¤ìŒ í›ˆë ¨:

```bash
# ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„
uv run cortexgpt/data/prepare_custom.py \
    --input your_data.jsonl \
    --output data/custom

# ì»¤ìŠ¤í…€ ë°ì´í„°ë¡œ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/custom/train.bin \
    --val-data data/custom/val.bin \
    --vocab-size 50257 \
    --epochs 50
```

#### ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì„¤ì •

ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë§¤ê°œë³€ìˆ˜ë¥¼ ì¡°ì •í•˜ì„¸ìš”:

```bash
# ë¹ ë¥¸ ì‹¤í—˜ì„ ìœ„í•œ ì‘ì€ ë©”ëª¨ë¦¬
uv run scripts/train_cortexgpt.py \
    --stm-capacity 32 \
    --ltm-dim 128 \
    --episodic-capacity 1000 \
    --batch-size 8 --epochs 10

# í”„ë¡œë•ì…˜ì„ ìœ„í•œ í° ë©”ëª¨ë¦¬
uv run scripts/train_cortexgpt.py \
    --stm-capacity 256 \
    --ltm-dim 512 \
    --episodic-capacity 50000 \
    --working-memory-slots 16 \
    --batch-size 4 --epochs 20
```

#### API ì‚¬ìš©ë²•

```python
import torch
from cortexgpt.models.cortex_gpt import CortexGPT, UnifiedCortexConfig
from cortexgpt.tokenization import MultilingualTokenizer

# í†µí•© ëª¨ë¸ ì´ˆê¸°í™”
config = UnifiedCortexConfig()
model = CortexGPT(config, vocab_size=50257, dim=768)

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
checkpoint = torch.load("checkpoints/cortex_unified/cortex_gpt_best.pt")
model.load_state_dict(checkpoint['model_state_dict'])

# í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = MultilingualTokenizer(vocab_size=50257)

# í…ìŠ¤íŠ¸ ìƒì„±
prompt = "ê¸°ê³„ í•™ìŠµì´ë€"
input_ids = tokenizer.encode(prompt)
output = model.generate(input_ids, max_length=100)
response = tokenizer.decode(output)
print(response)

# ëª¨ë¸ í†µê³„ í™•ì¸
stats = model.get_stats()
print(f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {stats['stm_usage']:.2%}")
print(f"í™œì„± ì»¬ëŸ¼: {stats['active_columns']}")
```

#### í›ˆë ¨ ëª¨ë‹ˆí„°ë§

Weights & Biasesë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸í•œ ëª¨ë‹ˆí„°ë§:

```bash
# ë¨¼ì € wandbì— ë¡œê·¸ì¸
wandb login

# ëª¨ë‹ˆí„°ë§ê³¼ í•¨ê»˜ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --wandb \
    --wandb-project "cortex-gpt-unified" \
    --wandb-entity "your-entity"
```

ëª¨ë‹ˆí„°ë§ í•­ëª©:
- í›ˆë ¨/ê²€ì¦ ì†ì‹¤
- í•™ìŠµë¥  ìŠ¤ì¼€ì¤„
- ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰
- ìƒ˜í”Œ ìƒì„±
- ì„±ëŠ¥ ë©”íŠ¸ë¦­

### ğŸŒ ì‹¤ì œ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨í•˜ê¸°

#### 1ë‹¨ê³„: ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡ ë³´ê¸°
uv run scripts/download_data.py --list

# íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
uv run scripts/download_data.py --dataset english_large
uv run scripts/download_data.py --dataset korean_large

# ëª¨ë“  ì˜ì–´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
uv run scripts/download_data.py --all --category english

# ëª¨ë“  í•œêµ­ì–´ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
uv run scripts/download_data.py --all --category korean
```

ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹:
- **ì˜ì–´**: english_small (5K), english_large (50K), wikitext, openwebtext, c4_en
- **í•œêµ­ì–´**: korean_small (5K), korean_large (50K), klue
- **ë°ëª¨**: demo (1K ìƒ˜í”Œ)

#### 2ë‹¨ê³„: ë°ì´í„° ì¤€ë¹„

í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë°”ì´ë„ˆë¦¬(.bin) íŒŒì¼ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤. JSONL íŒŒì¼ì´ ìˆë‹¤ë©´ ë¨¼ì € ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

#### 3ë‹¨ê³„: ì‹¤ì œ ë°ì´í„°ë¡œ í›ˆë ¨

##### í•œêµ­ì–´ ë°ì´í„°ì…‹ (KLUE)
```bash
# KLUE ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ (í†µí•© íŠ¸ë ˆì´ë„ˆ ì‚¬ìš©)
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --dim 512 \
    --batch-size 8 \
    --gradient-accumulation 4 \
    --lr 3e-4 \
    --epochs 10 \
    --wandb
```

##### ì˜ì–´ ë°ì´í„°ì…‹
```bash
# ë¨¼ì € ë°ì´í„° ì¤€ë¹„
uv run cortexgpt/data/prepare_data.py \
    --input-file data/datasets/english_large/data.jsonl \
    --output-file data/datasets/english_large/prepared/train.bin

# ëŒ€ê·œëª¨ ì˜ì–´ ë°ì´í„°ë¡œ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/english_large/prepared/train.bin \
    --val-data data/datasets/english_large/prepared/val.bin \
    --dim 512 \
    --batch-size 8 \
    --gradient-accumulation 4 \
    --lr 3e-4 \
    --epochs 10 \
    --wandb
```

##### í•œêµ­ì–´-ì˜ì–´ í˜¼í•© í›ˆë ¨
```bash
# ë¨¼ì € ë‘ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
uv run scripts/download_data.py --dataset english_large
uv run scripts/download_data.py --dataset korean_large

# ë¨¼ì € ê²°í•©ëœ ë°ì´í„°ì…‹ ì¤€ë¹„
uv run cortexgpt/data/prepare_multilingual.py \
    --korean-data data/datasets/klue/data.jsonl \
    --english-data data/datasets/english_large/data.jsonl \
    --output-dir data/datasets/combined/prepared \
    --korean-ratio 0.4

# ê²°í•©ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/combined/prepared/train.bin \
    --val-data data/datasets/combined/prepared/val.bin \
    --dim 768 \
    --vocab-size 50257 \
    --batch-size 4 \
    --gradient-accumulation 8 \
    --lr 2e-4 \
    --epochs 20 \
    --wandb
```

#### 4ë‹¨ê³„: í›ˆë ¨ ì¬ê°œ

í›ˆë ¨ì´ ì¤‘ë‹¨ëœ ê²½ìš°:

```bash
# íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --resume checkpoints/cortex_unified/cortex_gpt_best.pt \
    --wandb

# ë™ì¼í•œ ì„¤ì •ìœ¼ë¡œ ì¬ê°œ
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --resume checkpoints/cortex_unified/cortex_gpt_epoch_10.pt \
    --epochs 20  # 10 ì—í¬í¬ ì¶”ê°€ í›ˆë ¨
```

#### í›ˆë ¨ íŒ

1. **ì‘ê²Œ ì‹œì‘í•˜ê¸°**: í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ `--dim 256`ê³¼ `--vocab-size 10000`ìœ¼ë¡œ ì‹œì‘
2. **ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§**: OOM ë°œìƒ ì‹œ `--batch-size 2`ë¥¼ ì‚¬ìš©í•˜ê³  `--gradient-accumulation` ì¦ê°€
3. **í•™ìŠµë¥ **: ì‘ì€ ëª¨ë¸ì€ `1e-3`, í° ëª¨ë¸ì€ `3e-4`ë¡œ ì‹œì‘
4. **ì–´íœ˜ í¬ê¸°**: 
   - í•œêµ­ì–´ë§Œ: 20,000-30,000
   - ì˜ì–´ë§Œ: 30,000-40,000
   - í˜¼í•©: 40,000-50,000

#### âš¡ ë¹„ë™ê¸° ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•œ ë¹ ë¥¸ ë°ì´í„° ë¡œë”©

CortexGPTëŠ” ì´ì œ ë¹„ë™ê¸° ë©€í‹°í”„ë¡œì„¸ì‹±ì„ í†µí•´ ì´ˆê³ ì† ë°ì´í„° ë¡œë”©ì„ ì§€ì›í•©ë‹ˆë‹¤. ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì—ì„œ í›ˆë ¨ ì‹œì‘ê¹Œì§€ 20ë¶„ ì´ìƒ ê±¸ë¦¬ë˜ ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤:

```bash
# í›ˆë ¨ ì‹œ ìë™ìœ¼ë¡œ ë¹„ë™ê¸° ë¡œë”©ì„ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ ì‹œì‘
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/wikitext/prepared/train.bin \
    --val-data data/datasets/wikitext/prepared/val.bin \
    --num-workers 4 \
    --batch-size 8 \
    --epochs 10
```

íŠ¹ì§•:
- **ë³‘ë ¬ í† í¬ë‚˜ì´ì§•**: ì—¬ëŸ¬ ì›Œì»¤ê°€ ë™ì‹œì— ë°ì´í„°ë¥¼ í† í¬ë‚˜ì´ì¦ˆ
- **ë¹„ë™ê¸° ì²˜ë¦¬**: ì›Œì»¤ê°€ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ëŠ” ë™ì•ˆ ë©”ì¸ í”„ë¡œì„¸ìŠ¤ëŠ” ê³„ì† ì§„í–‰
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì **: ëª¨ë“  ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì§€ ì•Šê³  ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
- **ë¹ ë¥¸ ì‹œì‘**: ëª‡ ë¶„ì´ ì•„ë‹Œ ëª‡ ì´ˆ ë§Œì— í›ˆë ¨ ì‹œì‘

### ğŸ¯ v2.0ì˜ ì¤‘ìš”í•œ ë³€ê²½ì‚¬í•­

#### ë°ì´í„° í˜•ì‹
- **ë°”ì´ë„ˆë¦¬ í˜•ì‹ í•„ìš”**: í†µí•© íŠ¸ë ˆì´ë„ˆëŠ” JSONLì´ ì•„ë‹Œ `.bin` íŒŒì¼ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤
- **ë°ì´í„° ì¤€ë¹„**: JSONLì„ ë°”ì´ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ë ¤ë©´ `prepare_data.py` ì‚¬ìš©
- **ì§ì ‘ ê²½ë¡œ ì§€ì •**: `--dataset` ëŒ€ì‹  `--train-data`ì™€ `--val-data` ì‚¬ìš©

#### ì²´í¬í¬ì¸íŠ¸ ìœ„ì¹˜
- **ìƒˆ ìœ„ì¹˜**: `checkpoints/` ëŒ€ì‹  `checkpoints/cortex_unified/`
- **ëª…ëª… ê·œì¹™**: `cortex_gpt_best.pt`, `cortex_gpt_epoch_N.pt`
- **í•˜ìœ„ í˜¸í™˜ì„±**: ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ë„ ë¡œë“œ ê°€ëŠ¥

#### ê¸°ë³¸ ë™ì‘
- **ëª¨ë“  Phase í™œì„±í™”**: Phase 1-3 ê¸°ëŠ¥ì´ ê¸°ë³¸ì ìœ¼ë¡œ í™œì„±í™”ë¨
- **GPU ë©”ëª¨ë¦¬**: ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ìë™ìœ¼ë¡œ GPU ê°€ì† ì‚¬ìš©
- **ìµœì†Œ ëª¨ë“œ**: ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ì„ ë¹„í™œì„±í™”í•˜ë ¤ë©´ `--minimal` ì‚¬ìš©

#### ğŸš€ ì‹ ê·œ: ìµœì í™”ëœ Training (v2.1)

**ë” ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ trainingì„ ìœ„í•œ ì£¼ìš” ê°œì„ ì‚¬í•­:**
- **Learning rate ë¬¸ì œ í•´ê²°** - ì´ì „ ë²„ì „ì€ learning rateê°€ 1000ë°° ì‘ì•˜ìŒ
- **Data loading ìµœì í™”** - ì ì ˆí•œ multi-worker ì„¤ì •ìœ¼ë¡œ 20ë°° ë¹ ë¦„
- **ìŠ¤ë§ˆíŠ¸ GPU ê°ì§€** - í•˜ë“œì›¨ì–´ì— ë§ê²Œ ìë™ ì„¤ì •

```bash
# ì¶”ì²œ: ìµœì í™”ëœ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ training
uv run scripts/train.py --mode fast --epochs 10 --wandb

# Custom data ì‚¬ìš©ì‹œ
uv run scripts/train.py \
    --train-data data/your_train.bin \
    --val-data data/your_val.bin \
    --mode fast \
    --epochs 10
```

**ìë™ ê°ì§€ GPU ì„¤ì • (ìˆ˜ì •ëœ learning rate í¬í•¨):**
- **RTX 3090** (24GB): Batch 12, dim 512, LR 1e-4, 8 workers
- **RTX 3080** (10GB): Batch 8, dim 384, LR 1e-4, 6 workers
- **RTX 3070** (8GB): Batch 4, dim 256, LR 1e-4, 4 workers
- **ê¸°íƒ€ GPU**: ì‚¬ìš© ê°€ëŠ¥í•œ memoryì— ë”°ë¼ ìë™ ì„¤ì •

**ë©”ëª¨ë¦¬ ìµœì í™” ê¸°ëŠ¥:**
- ë” í° íš¨ê³¼ì ì¸ ë°°ì¹˜ í¬ê¸°ë¥¼ ìœ„í•œ ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì 
- í˜¼í•© ì •ë°€ë„ í›ˆë ¨ (FP16)
- ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…
- ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ì˜¤í”„ë¡œë”© (ì„ íƒì‚¬í•­)

#### ğŸ§  ê³ ê¸‰ ê¸°ëŠ¥ Training

Neuroscienceì™€ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ standard ë˜ëŠ” full modeë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:

```bash
# Standard modeëŠ” Phase 1 + homeostasis í¬í•¨
uv run scripts/train.py --mode standard --epochs 20

# Full modeëŠ” ëª¨ë“  ê¸°ëŠ¥ í¬í•¨ (20GB+ memory í•„ìš”)
uv run scripts/train.py --mode full --epochs 20

# GPU memory ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

**ë‡Œê³¼í•™ ê¸°ëŠ¥ ìˆ˜ë™ ì„¤ì •:**
```bash
# ìµœì†Œ neuroscience - í•­ìƒì„±ë§Œ (12-15GB ë©”ëª¨ë¦¬)
uv run scripts/train_cortexgpt.py \
    --batch-size 8 \
    --gradient-accumulation 2 \
    --dim 512 \
    --stm-capacity 64 \
    --cortical-columns 8 \
    --enable-homeostasis \
    --minimal \
    --epochs 20

# ì¤‘ê°„ neuroscience - í•­ìƒì„± + ìˆ˜ë©´-ê°ì„± (15-18GB ë©”ëª¨ë¦¬)
uv run scripts/train_cortexgpt.py \
    --batch-size 6 \
    --gradient-accumulation 3 \
    --dim 512 \
    --enable-homeostasis \
    --enable-sleep-wake \
    --consolidation-cycle 1000 \
    --minimal \
    --epochs 20
```

**ê¸°ëŠ¥ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:**
- ê¸°ë³¸ ëª¨ë¸ (ìµœì†Œ): ~8-10GB
- + í•­ìƒì„±: +3-4GB
- + ìˆ˜ë©´-ê°ì„± ì£¼ê¸°: +3-4GB
- + ë³´ì™„ í•™ìŠµ: +2-3GB
- + Phase 3 (ì—í”¼ì†Œë”•/ì‘ì—… ë©”ëª¨ë¦¬): +5-8GB

**âš ï¸ ì¤‘ìš” ì‚¬í•­:**
- ëª¨ë“  ê¸°ëŠ¥ì´ í™œì„±í™”ëœ ê¸°ë³¸ êµ¬ì„±ì€ >20GB ë©”ëª¨ë¦¬ ì‚¬ìš©
- RTX 3090ì˜ ê²½ìš° ìœ„ì˜ ë‡Œê³¼í•™ ìŠ¤í¬ë¦½íŠ¸ë‚˜ ìˆ˜ë™ êµ¬ì„± ì‚¬ìš©
- `watch -n 1 nvidia-smi`ë¡œ GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
- OOM ë°œìƒ ì‹œ ê¸°ëŠ¥ì„ í•˜ë‚˜ì”© ë¹„í™œì„±í™”

### ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | ì–¸ì–´ | ìƒ˜í”Œ ìˆ˜ | ì„¤ëª… |
|---------|------|---------|------|
| `demo` | í˜¼í•© | 1K | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš© ì‘ì€ ë°ì´í„°ì…‹ |
| `english_small` | ì˜ì–´ | 5K | ì†Œê·œëª¨ ì˜ì–´ í…ìŠ¤íŠ¸ |
| `english_large` | ì˜ì–´ | 50K | ëŒ€ê·œëª¨ ì˜ì–´ í…ìŠ¤íŠ¸ |
| `korean_small` | í•œêµ­ì–´ | 5K | ì†Œê·œëª¨ í•œêµ­ì–´ í…ìŠ¤íŠ¸ |
| `korean_large` | í•œêµ­ì–´ | 50K | ëŒ€ê·œëª¨ í•œêµ­ì–´ í…ìŠ¤íŠ¸ |
| `wikitext` | ì˜ì–´ | 10K | WikiText-103 ë°ì´í„°ì…‹ |
| `openwebtext` | ì˜ì–´ | 10K | OpenWebText ë°ì´í„°ì…‹ |
| `c4_en` | ì˜ì–´ | 5K | C4 ì˜ì–´ ë°ì´í„°ì…‹ |
| `klue` | í•œêµ­ì–´ | 10K | í•œêµ­ì–´ ì–¸ì–´ ì´í•´ í‰ê°€ |
| `combined` | í˜¼í•© | - | í•œêµ­ì–´+ì˜ì–´ ì¡°í•© |

### ğŸ—ï¸ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
my-efficient-gpt/
â”œâ”€â”€ cortexgpt/              # Main package
â”‚   â”œâ”€â”€ models/            # Model architectures
â”‚   â”œâ”€â”€ learning/          # Real-time learning system
â”‚   â”œâ”€â”€ tokenization/      # Multilingual tokenizer
â”‚   â”œâ”€â”€ data/             # Data loading utilities
â”‚   â””â”€â”€ training/         # Training scripts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data/             # Data preparation scripts
â”‚   â””â”€â”€ demos/            # Demo applications
â”œâ”€â”€ tests/                # Test scripts
â”œâ”€â”€ docs/                 # Documentation
â””â”€â”€ data/                 # Training data
```

### ğŸ“š ë¬¸ì„œ

ëª¨ë“  ê¸°ìˆ  ë¬¸ì„œê°€ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤:

- **[ë¬¸ì„œ í—ˆë¸Œ](docs/README.md)** - ëª¨ë“  ê°€ì´ë“œì™€ ê¸°ìˆ  ë¬¸ì„œë¥¼ ìœ„í•œ ì¤‘ì•™ ë„¤ë¹„ê²Œì´ì…˜
- **[Training ê°€ì´ë“œ](docs/guides/TRAINING_GUIDE.md)** - ì™„ì „í•œ training ì§€ì¹¨
- **[Training ìµœì í™”](docs/guides/TRAINING_OPTIMIZATION.md)** - ì„±ëŠ¥ íŠœë‹ ê°€ì´ë“œ
- **[ì•„í‚¤í…ì²˜ ê°œìš”](docs/guides/architecture.md)** - ê¸°ìˆ  ì•„í‚¤í…ì²˜ ì„¸ë¶€ì‚¬í•­
- **[ê°œë°œ í˜„í™©](docs/development/PROJECT_STATUS.md)** - í˜„ì¬ í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©

ì „ì²´ ë¬¸ì„œëŠ” [docs ë””ë ‰í† ë¦¬](docs/)ë¥¼ ë°©ë¬¸í•˜ì„¸ìš”.

### ğŸ’¡ ì‘ë™ ì›ë¦¬

#### ë©”ëª¨ë¦¬ íë¦„
```
ìƒˆë¡œìš´ ì…ë ¥ â†’ STM (ë¹ ë¥¸ ì ‘ê·¼)
     â†“ (ìì£¼ ì‚¬ìš©)
    LTM (í†µí•©ëœ ì§€ì‹)
     â†“ (ì˜¤ë˜ ë¯¸ì‚¬ìš©)
   Archive (ì••ì¶• ì €ì¥)
```

#### í•™ìŠµ ê³¼ì •
1. **ì²« ì§ˆë¬¸**: "ì•„ì§ í•™ìŠµí•˜ì§€ ëª»í•œ ë‚´ìš©ì…ë‹ˆë‹¤"
2. **í•™ìŠµ í›„**: ì •í™•í•œ ë‹µë³€ ì œê³µ
3. **ë°˜ë³µ ì‹œ**: ì‹ ë¢°ë„ ì¦ê°€ (0.6 â†’ 0.9 â†’ 1.0)

### ğŸ“ˆ í›ˆë ¨ ì˜µì…˜

```bash
# ëª¨ë¸ ì•„í‚¤í…ì²˜
--dim               # íˆë“  ì°¨ì› (256/512/768, ê¸°ë³¸ê°’: 768)
--vocab-size        # í† í¬ë‚˜ì´ì € ì–´íœ˜ í¬ê¸° (ê¸°ë³¸ê°’: 50257)
--cortical-columns  # í”¼ì§ˆ ì»¬ëŸ¼ ìˆ˜ (ê¸°ë³¸ê°’: 16)
--sparsity-ratio   # ì»¬ëŸ¼ì˜ í¬ì†Œì„± ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.05)

# í›ˆë ¨ íŒŒë¼ë¯¸í„°
--batch-size        # ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 16)
--gradient-accumulation  # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ë‹¨ê³„ (ê¸°ë³¸ê°’: 4)
--epochs           # ì—í­ ìˆ˜ (ê¸°ë³¸ê°’: 20)
--lr              # í•™ìŠµë¥  (ê¸°ë³¸ê°’: 5e-5)
--warmup-ratio    # ì›Œë°ì—… ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)
--weight-decay    # ê°€ì¤‘ì¹˜ ê°ì‡  (ê¸°ë³¸ê°’: 0.1)
--grad-clip       # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ (ê¸°ë³¸ê°’: 1.0)

# Phase ì„ íƒ
--enable-phase1    # Phase 1 ì•ˆì •ì„± ê¸°ëŠ¥ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-phase2    # Phase 2 ë‡Œê³¼í•™ ê¸°ëŠ¥ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-phase3    # Phase 3 ì„±ëŠ¥ ê¸°ëŠ¥ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--minimal         # ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”

# Phase 1: ì•ˆì •ì„± ê¸°ëŠ¥
--memory-temperature    # ë©”ëª¨ë¦¬ ê²Œì´íŒ… ì˜¨ë„ (ê¸°ë³¸ê°’: 1.0)
--use-stop-gradient    # ë©”ëª¨ë¦¬ ê²€ìƒ‰ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ ì¤‘ë‹¨ (ê¸°ë³¸ê°’: True)
--memory-dropout       # ë©”ëª¨ë¦¬ ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.1)
--residual-weight     # ì”ì°¨ ì—°ê²° ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: 0.1)

# Phase 2: neuroscience ê¸°ëŠ¥
--enable-homeostasis   # í•­ìƒì„± ê°€ì†Œì„± í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-sleep-wake    # ìˆ˜ë©´-ê°ì„± ì£¼ê¸° í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-cls          # ë³´ì™„ í•™ìŠµ ì‹œìŠ¤í…œ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--target-firing-rate  # í•­ìƒì„± ëª©í‘œ ë°œí™”ìœ¨ (ê¸°ë³¸ê°’: 0.1)
--consolidation-cycle # ìˆ˜ë©´-ê°ì„± ì£¼ê¸°ë‹¹ ë‹¨ê³„ (ê¸°ë³¸ê°’: 1000)

# Phase 3: ì„±ëŠ¥ ê¸°ëŠ¥
--use-gpu-memory      # GPU ê°€ì† ë©”ëª¨ë¦¬ ì‚¬ìš© (ê¸°ë³¸ê°’: True)
--async-memory        # ë¹„ë™ê¸° ë©”ëª¨ë¦¬ ì‘ì—… í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-episodic     # ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--enable-working      # ì‘ì—… ë©”ëª¨ë¦¬ í™œì„±í™” (ê¸°ë³¸ê°’: True)
--episodic-capacity   # ì—í”¼ì†Œë“œ ë©”ëª¨ë¦¬ ìš©ëŸ‰ (ê¸°ë³¸ê°’: 10000)
--working-memory-slots # ì‘ì—… ë©”ëª¨ë¦¬ ìŠ¬ë¡¯ (ê¸°ë³¸ê°’: 8)

# ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ
--stm-capacity     # ë‹¨ê¸° ê¸°ì–µ ìš©ëŸ‰ (ê¸°ë³¸ê°’: 128)
--ltm-dim         # ì¥ê¸° ê¸°ì–µ ì°¨ì› (ê¸°ë³¸ê°’: 256)

# ëª¨ë‹ˆí„°ë§ ë° ì²´í¬í¬ì¸íŒ…
--wandb           # Weights & Biases ë¡œê¹… í™œì„±í™”
--wandb-project   # W&B í”„ë¡œì íŠ¸ ì´ë¦„ (ê¸°ë³¸ê°’: cortex-gpt-unified)
--checkpoint-dir  # ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: checkpoints/cortex_unified)
--resume         # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ (auto/ê²½ë¡œ)
--seed           # ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
```

### ğŸš€ ê¶Œì¥ í›ˆë ¨ ì„¤ì •

#### í…ŒìŠ¤íŠ¸ ë° ê°œë°œ
```bash
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì‘ì€ ëª¨ë¸ (ê¸°ë³¸ ì„¤ì •)
uv run scripts/train_cortexgpt.py \
    --dim 256 --lr 1e-3 --batch-size 4 --epochs 5 \
    --minimal  # ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”
```

#### ë°ëª¨ í›ˆë ¨
```bash
# ê¸°ë³¸ ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¤‘ê°„ ëª¨ë¸
uv run scripts/train_cortexgpt.py \
    --dim 512 --lr 5e-4 --batch-size 8 --epochs 10
    
# íŠ¹ì • phase ê¸°ëŠ¥ê³¼ í•¨ê»˜
uv run scripts/train_cortexgpt.py \
    --dim 512 --batch-size 8 \
    --enable-phase1 --memory-temperature 2.0 \
    --enable-phase2 --enable-homeostasis
```

#### í”„ë¡œë•ì…˜ í›ˆë ¨
```bash
# KLUE ë°ì´í„°ì…‹ìœ¼ë¡œ í° ëª¨ë¸ (ëª¨ë“  ê¸°ëŠ¥ ê¸°ë³¸ í™œì„±í™”)
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --dim 768 --lr 3e-4 --batch-size 4 --gradient-accumulation 8 \
    --epochs 20 --wandb

# ë˜ëŠ” ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --use-gpu-memory --async-memory \
    --enable-episodic --enable-working \
    --wandb
```

#### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
```bash
# ìµœëŒ€ ì„±ëŠ¥ ì„¤ì •
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --dim 768 --batch-size 16 \
    --use-gpu-memory --async-memory \
    --episodic-capacity 50000 \
    --working-memory-slots 16 \
    --num-workers 8
```

### ğŸš€ BGE-M3 í•˜ì´ë¸Œë¦¬ë“œ ì„ë² ë”© (ê¸°ë³¸ í™œì„±í™”)

CortexGPTëŠ” ìš°ìˆ˜í•œ ë‹¤êµ­ì–´ ì´í•´ë¥¼ ìœ„í•´ ìµœì²¨ë‹¨ BGE-M3 ì„ë² ë”©ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤:

#### íŠ¹ì§•
- **100ê°œ ì´ìƒ ì–¸ì–´ ì§€ì›**: í•œêµ­ì–´ì™€ ì˜ì–´ë¥¼ ë„˜ì–´ì„œ
- **8192 í† í° ì»¨í…ìŠ¤íŠ¸**: í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°
- **ë‹¤ê¸°ëŠ¥ì„±**: ë°€ì§‘, í¬ì†Œ, ë‹¤ì¤‘ ë²¡í„° ê²€ìƒ‰
- **ë©”ëª¨ë¦¬ ì¸ì‹ í†µí•©**: CortexGPTì˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œê³¼ ê²°í•©

#### BGE-M3ë¡œ í›ˆë ¨í•˜ê¸°

```bash
# 1ë‹¨ê³„: ì–´ëŒ‘í„°ë§Œ í›ˆë ¨ (BGE ë™ê²°)
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --bge-stage 1 \
    --epochs 10

# 2ë‹¨ê³„: ì „ì²´ ë¯¸ì„¸ì¡°ì • (ì„ íƒì‚¬í•­)
uv run scripts/train_cortexgpt.py \
    --train-data data/datasets/klue/prepared/train.bin \
    --val-data data/datasets/klue/prepared/val.bin \
    --bge-stage 2 \
    --epochs 5 \
    --resume checkpoints/cortex_unified/cortex_gpt_best.pt
```

### ğŸ”¬ ì—°êµ¬ ë° ê°œë°œ

CortexGPT v2.0ì€ ê³ ê¸‰ ë‡Œê³¼í•™ ê°œë…ì„ êµ¬í˜„í•©ë‹ˆë‹¤:

**í•µì‹¬ ê°œë…**:
- **í—¤ë¹„ì•ˆ í•™ìŠµ**: "í•¨ê»˜ ë°œí™”í•˜ëŠ” ë‰´ëŸ°ì€ í•¨ê»˜ ì—°ê²°ëœë‹¤"
- **ë©”ëª¨ë¦¬ í†µí•©**: STMì—ì„œ LTMìœ¼ë¡œì˜ ì ì§„ì  ì „ì´
- **ì„ íƒì  ì£¼ì˜**: ê´€ë ¨ ì •ë³´ì— ì§‘ì¤‘
- **ì§€ì†ì  í•™ìŠµ**: ìŠì§€ ì•Šê³  ìƒˆë¡œìš´ ì‘ì—… í•™ìŠµ

**Phase 1 - ì•ˆì •ì„± ë©”ì»¤ë‹ˆì¦˜**:
- **ì˜¨ë„ ì œì–´**: ë©”ëª¨ë¦¬ ê²Œì´íŠ¸ì—ì„œ íŒŒêµ­ì ì¸ ìŠ¹ìë…ì‹ ë°©ì§€
- **ê·¸ë˜ë””ì–¸íŠ¸ ì¤‘ë‹¨**: ë©”ëª¨ë¦¬ ê²€ìƒ‰ì—ì„œ ë¶ˆì•ˆì •í•œ í”¼ë“œë°± ë£¨í”„ ì œê±°
- **ë¶€ë“œëŸ¬ìš´ í¬ì†Œì„±**: Gumbel-Softmaxë¥¼ í†µí•œ ë§¤ë„ëŸ¬ìš´ ê·¸ë˜ë””ì–¸íŠ¸ íë¦„
- **ì†ì‹¤ ë³µêµ¬**: í›ˆë ¨ ë¶ˆì•ˆì •ì„±ì˜ ìë™ ê°ì§€ ë° ë³µêµ¬

**Phase 2 - Brain-inspired features**:
- **Homeostatic plasticity**: ì•ˆì •ì ì¸ neuron firing rate ìœ ì§€ (ëª©í‘œ: 0.1)
- **Sleep-wake cycles**: 3ë‹¨ê³„ consolidation (Wake â†’ NREM â†’ REM)
- **Complementary Learning Systems**: ë¹ ë¥¸ hippocampal vs ëŠë¦° neocortical pathways
- **BCM metaplasticity**: Synaptic modificationì„ ìœ„í•œ sliding threshold

**Phase 3 - Cognitive architecture**:
- **FAISS GPU memory**: Similarity searchì—ì„œ 35ë°° ì†ë„ í–¥ìƒ
- **Episodic memory**: Temporal sequence learning ë° recall
- **Working memory**: Task-specific attention gates
- **Hierarchical compression**: Progressive memory abstraction
- **Cognitive features**: Analogy detection, causal reasoning, concept formation

### ğŸ“ ì¸ìš©

```bibtex
@software{cortexgpt2025,
  author = {Ruo Lee},
  title = {CortexGPT: Real-time Learning Language Model},
  year = {2025},
  email = {comsa333@gmail.com}
}
```

### ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT ë¼ì´ì„ ìŠ¤ - ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

---

Made with â¤ï¸ by Ruo Lee